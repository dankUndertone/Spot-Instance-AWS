{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spot Instances\n",
    "\n",
    "**Execute a script**\n",
    "https://peteris.rocks/blog/script-to-launch-amazon-ec2-spot-instances/\n",
    "\n",
    "**Open a Notebook**\n",
    "https://chrisalbon.com/aws/basics/run_project_jupyter_on_amazon_ec2/\n",
    "\n",
    "*There are programmatic ways to retrieve both pricing and the launch wizard but these can take time so for a quick reference refer to the solutions below.*\n",
    "\n",
    "**Prices** : https://aws.amazon.com/ec2/spot/pricing/\n",
    "<br>**Images** : go to the launch-wizard to get the image IDs or use the boto3 client.describe_images() with Owners of Filters parameters to reduce wait time and find what you need.\n",
    "\n",
    "**Storage**: storage options for spot instances include S3, EBS and EFS. Spot instances can be optimized for EBS. For a breakdown of storage options read [this](https://dzone.com/articles/confused-by-aws-storage-options-s3-ebs-amp-efs-explained) article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"b'l'b's\\r\\n'b'\\x1b[0m\\x1b[01;34manaconda3\\x1b[0m        \\x1b[01;34mexamples\\x1b[0m               README  \\x1b[01;34mtools\\x1b[0m\\r\\n'b'\\x1b[34;42mefs-mount-point\\x1b[0m  Nvidia_Cloud_EULA.pdf  \\x1b[01;34msrc\\x1b[0m     \\x1b[01;34mtutorials\\x1b[0m\\r\\n'b'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "ansi_escape = re.compile(r'\\x1B[@-_][0-?]*[ -/]*[@-~]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"b'l'b's\\r\\n'b'anaconda3        examples               README  tools\\r\\n'b'efs-mount-point  Nvidia_Cloud_EULA.pdf  src     tutorials\\r\\n'b'\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ansi_escape.sub('', string).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spot_connect as sc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting...\n",
      "Connected\n"
     ]
    }
   ],
   "source": [
    "ssh_client = sc.connect_to_instance('52.36.226.213','KP-test',username='ec2-user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = ssh_client.get_transport().open_session()\n",
    "session.get_pty()\n",
    "session.invoke_shell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line-buffered terminal emulation. Press F6 or ^Z to send EOF.\n",
      "\n",
      "=============================================================================\n",
      "       __|  __|_  )\n",
      "       _|  (     /   Deep Learning AMI (Amazon Linux) Version 24.0\n",
      "      ___|\\___|___|\n",
      "=============================================================================\n",
      "\n",
      "Please use one of the following commands to start the required environment with the framework of your choice:\n",
      "for MXNet(+Keras2) with Python3 (CUDA 10.0 and Intel MKL-DNN) _____________________________________ source activate mxnet_p36\n",
      "for MXNet(+Keras2) with Python2 (CUDA 10.0 and Intel MKL-DNN) _____________________________________ source activate mxnet_p27\n",
      "for MXNet(+Amazon Elastic Inference) with Python3 _______________________________________ source activate amazonei_mxnet_p36\n",
      "for MXNet(+Amazon Elastic Inference) with Python2 _______________________________________ source activate amazonei_mxnet_p27\n",
      "for TensorFlow(+Keras2) with Python3 (CUDA 10.0 and Intel MKL-DNN) ___________________________ source activate tensorflow_p36\n",
      "for TensorFlow(+Keras2) with Python2 (CUDA 10.0 and Intel MKL-DNN) ___________________________ source activate tensorflow_p27\n",
      "for Tensorflow(+Amazon Elastic Inference) with Python2 _____________________________ source activate amazonei_tensorflow_p27\n",
      "for Tensorflow(+Amazon Elastic Inference) with Python3 _____________________________ source activate amazonei_tensorflow_p36\n",
      "for Theano(+Keras2) with Python3 (CUDA 9.0) _____________________________________________________ source activate theano_p36\n",
      "for Theano(+Keras2) with Python2 (CUDA 9.0) _____________________________________________________ source activate theano_p27\n",
      "for PyTorch with Python3 (CUDA 10.0 and Intel MKL) _____________________________________________ source activate pytorch_p36\n",
      "for PyTorch with Python2 (CUDA 10.0 and Intel MKL) _____________________________________________ source activate pytorch_p27\n",
      "for CNTK(+Keras2) with Python3 (CUDA 9.0 and Intel MKL-DNN) _______________________________________ source activate cntk_p36\n",
      "for CNTK(+Keras2) with Python2 (CUDA 9.0 and Intel MKL-DNN) _______________________________________ source activate cntk_p27\n",
      "for Caffe2 with Python2 (CUDA 9.0) ______________________________________________________________ source activate caffe2_p27\n",
      "for Caffe with Python2 (CUDA 8.0) ________________________________________________________________ source activate caffe_p27\n",
      "for Caffe with Python3 (CUDA 8.0) ________________________________________________________________ source activate caffe_p35\n",
      "for Chainer with Python2 (CUDA 10.0 and Intel iDeep) ____________________________________________ source activate chainer_p27\n",
      "for Chainer with Python3 (CUDA 10.0 and Intel iDeep) ____________________________________________ source activate chainer_p36\n",
      "for base Python2 (CUDA 9.0) ________________________________________________________________________ source activate python2\n",
      "for base Python3 (CUDA 9.0) ________________________________________________________________________ source activate python3\n",
      "\n",
      "Official Conda User Guide: https://docs.conda.io/projects/conda/en/latest/user-guide/\n",
      "AWS Deep Learning AMI Homepage: https://aws.amazon.com/machine-learning/amis/\n",
      "Developer Guide and Release Notes: https://docs.aws.amazon.com/dlami/latest/devguide/what-is-dlami.html\n",
      "Support: https://forums.aws.amazon.com/forum.jspa?forumID=263\n",
      "For a fully managed experience, check out Amazon SageMaker at https://aws.amazon.com/sagemaker\n",
      "=============================================================================\n",
      "11 package(s) needed for security, out of 17 available\n",
      "Run \"sudo yum update\" to apply all updates.\n",
      "[ec2-user@ip-172-31-6-188 ~]$ "
     ]
    }
   ],
   "source": [
    "interactive.interactive_shell(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_prompt(instance, user_name, port=22):\n",
    "    client = connect_to_instance(instance['PublicIpAddress'],instance['KeyName'],username=user_name,port=port)\n",
    "    print('Instance prompt open, using image OS. Type \"exit\" to end active prompt session')\n",
    "    command='pwd'\n",
    "    stdin, stdout, stderr = client.exec_command(command)                                      # Execute a command or .sh script (unix or linux console)\n",
    "    try:\n",
    "        currdir = ''\n",
    "        for line in stdout:\n",
    "            currdir+=line.rstrip()                                           # Show the output \n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        print(sys.stderr, 'Ctrl-C, stopping')\n",
    "\n",
    "    while command!=\"exit\":\n",
    "        command = input(str(currdir)+' > ')\n",
    "        stdin.write(command)\n",
    "        stdin.flush()\n",
    "        data = stdout.read.splitlines()\n",
    "        for line in data:\n",
    "            print(line.rstrip())\n",
    "            \n",
    "    client.close()                                                           # Close the connection \n",
    "    print('Exit code: 0')\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import time \n",
    "import boto3\n",
    "\n",
    "region='us-west-2'\n",
    "datasync_instance_name='datasync'\n",
    "instance_filters={}\n",
    "sg_filters={}\n",
    "fs_creation_token=None\n",
    "s3_bucket=None\n",
    "use_first_bucket=True\n",
    "use_first_role=True\n",
    "datasync_wait=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('ec2',region_name=region)                            # Connect to regional ec2 subnet \n",
    "instances = client.describe_instances()['Reservations']                    # Get the first instance with the keyname matching the datasync name \n",
    "instance = [instance['Instances'][0] for instance in instances if datasync_instance_name in instance['Instances'][0]['KeyName']][0]\n",
    "\n",
    "owner_id = instance['NetworkInterfaces'][0]['OwnerId']                     # The owner of the instance is the owner of the entire account so we fix the owner id \n",
    "\n",
    "subnet_id = instance['SubnetId']                                           # Get the ID for the ec2 subnet \n",
    "\n",
    "sg = client.describe_security_groups(Filters=[sg_filters])['SecurityGroups'][0]\n",
    "sg_id = sg['GroupId']                                                      # Get the GroupId for the security groups that match the filter parameters (first of all if no filters submitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('efs',region_name=region)                            # Connect to the elastic file system \n",
    "if fs_creation_token is None:\n",
    "    filesystem = client.describe_file_systems()['FileSystems'][0]          # Retrieve the first file system \n",
    "else:                                                                      # or the first that matches the creation token submitted \n",
    "    filesystem = client.describe_file_systems(CreationToken=fs_creation_token)['FileSystems'][0]\n",
    "fs_id = filesystem['FileSystemId']\n",
    "\n",
    "mount_target = client.describe_mount_targets(FileSystemId=fs_id)['MountTargets'][0]\n",
    "mount_ip = mount_target['IpAddress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.resource('s3', region_name=region)                          # \n",
    "buckets = list(client.buckets.all())\n",
    "if s3_bucket is None: \n",
    "    if use_first_bucket: \n",
    "        bucket_name = buckets[0].name\n",
    "    else: \n",
    "        print('These are the S3 buckets in this region:')\n",
    "        print(list(enumerate(buckets)))\n",
    "        selection = input('Type the number of the bucket you want to use: ')\n",
    "        bucket_name = buckets[int(selection)].name\n",
    "else: \n",
    "    bucket_name = s3_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.resource('iam', region_name=region)\n",
    "roles = list(client.roles.all())\n",
    "if use_first_role: \n",
    "    role_name = roles[0].name\n",
    "else: \n",
    "    print(\"These are the roles in this region:\")\n",
    "    print(list(enumerate(roles)))\n",
    "    selection = input('Type the number of the role you want to use: ')\n",
    "    role_name = roles[int(selection)].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subnet_arn = 'arn:aws:ec2:'+region+':'+owner_id+':subnet/'+subnet_id\n",
    "sg_arn = 'arn:aws:ec2:'+region+':'+owner_id+':security-group/'+sg_id\n",
    "efs_arn = 'arn:aws:elasticfilesystem:'+region+':'+owner_id+':file-system/'+fs_id\n",
    "bucket_arn = 'arn:aws:s3:::'+bucket_name\n",
    "accessrole_arn = 'arn:aws:iam::'+owner_id+':role/'+role_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('datasync',region_name=region)\n",
    "\n",
    "online_agents = [agent for agent in client.list_agents()['Agents'] if agent['Status']=='ONLINE']\n",
    "print('Retrieving online agent...')\n",
    "if len(online_agents)==0:\n",
    "    print('None found. Creating agent...')\n",
    "    public_ip = instance['PublicIpAddress']\n",
    "    r = requests.get(\"http://\"+public_ip+\"/?gatewayType=SYNC&activationRegion=\"+region+\"&no_redirect\")\n",
    "    activation_key = r.text\n",
    "\n",
    "    response = client.create_agent(\n",
    "        ActivationKey=activation_key,\n",
    "    )\n",
    "    agent_arn = response['AgentArn']\n",
    "    while len(online_agents)<1:\n",
    "        print('.')\n",
    "        online_agents = [agent for agent in client.list_agents()['Agents'] if agent['Status']=='ONLINE']    \n",
    "        if len(online_agents)<1:\n",
    "            time.sleep(datasync_wait)\n",
    "        else: \n",
    "            print('Agent Online')\n",
    "else: \n",
    "    agent_arn = online_agents[0]['AgentArn']\n",
    "    print('Agent found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = client.list_locations()['Locations']\n",
    "s3_locations = [location for location in locations if bucket_name in location['LocationUri']]\n",
    "print('Retrieving S3 Location...')\n",
    "if len(s3_locations)==0:\n",
    "    response = client.create_location_s3(\n",
    "        S3BucketArn=bucket_arn,\n",
    "        S3Config={\n",
    "            'BucketAccessRoleArn': accessrole_arn\n",
    "        },\n",
    "    )\n",
    "    s3_location = response['LocationArn']\n",
    "    while len(s3_locations)<1:\n",
    "        print('.')\n",
    "        locations = client.list_locations()['Locations']\n",
    "        s3_locations = [location for location in locations if bucket_name in location['LocationUri']]\n",
    "        if len(s3_locations)<1:\n",
    "            time.sleep(datasync_wait)\n",
    "        else: \n",
    "            print('S3 Location \"%s\" Retrieved' % str(bucket_name))\n",
    "else: \n",
    "    s3_location = s3_locations[0]['LocationArn']\n",
    "    print('S3 Location \"%s\" Retrieved' % str(bucket_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Retrieving Elastic File System Location...')\n",
    "locations = client.list_locations()['Locations']\n",
    "fs_locations = [location for location in locations if mount_ip in location['LocationUri']]\n",
    "if len(fs_locations)==0: \n",
    "    response = client.create_location_nfs(\n",
    "        Subdirectory='/',\n",
    "        ServerHostname=mount_ip,\n",
    "        OnPremConfig={\n",
    "            'AgentArns': [agent_arn]\n",
    "        }\n",
    "    )\n",
    "    efs_location = response['LocationArn']\n",
    "    while len(fs_locations)<1:\n",
    "        print('.')\n",
    "        locations = client.list_locations()['Locations']\n",
    "        fs_locations = [location for location in locations if mount_ip in location['LocationUri']]\n",
    "        if len(fs_locations)<1:\n",
    "            time.sleep(datasync_wait)\n",
    "        else: \n",
    "            print('EFS Location \"%s\" Online' % filesystem['CreationToken'])\n",
    "else:\n",
    "    efs_location = fs_locations[0]['LocationArn']\n",
    "    print('EFS Location \"%s\" Online' % filesystem['CreationToken'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('datasync', region_name=region)\n",
    "response = client.create_task(\n",
    "    SourceLocationArn=s3_location,\n",
    "    DestinationLocationArn=efs_location,\n",
    "    Name='UploadToEfs',\n",
    ")\n",
    "task_arn = client.list_tasks()['Tasks'][0]['TaskArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.start_task_execution(\n",
    "    TaskArn=task_arn,\n",
    ")\n",
    "task_exec_arn = response['TaskExecutionArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BytesTransferred': 0,\n",
       " 'BytesWritten': 0,\n",
       " 'EstimatedBytesToTransfer': 0,\n",
       " 'EstimatedFilesToTransfer': 0,\n",
       " 'Excludes': [],\n",
       " 'FilesTransferred': 0,\n",
       " 'Includes': [],\n",
       " 'Options': {'Atime': 'BEST_EFFORT',\n",
       "  'BytesPerSecond': -1,\n",
       "  'Gid': 'INT_VALUE',\n",
       "  'Mtime': 'PRESERVE',\n",
       "  'PosixPermissions': 'PRESERVE',\n",
       "  'PreserveDeletedFiles': 'PRESERVE',\n",
       "  'PreserveDevices': 'NONE',\n",
       "  'Uid': 'INT_VALUE',\n",
       "  'VerifyMode': 'POINT_IN_TIME_CONSISTENT'},\n",
       " 'ResponseMetadata': {'HTTPHeaders': {'connection': 'keep-alive',\n",
       "   'content-length': '607',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Tue, 10 Sep 2019 16:12:26 GMT',\n",
       "   'x-amzn-requestid': '2bc9fada-b81d-4a48-973a-a902dc8e1fda'},\n",
       "  'HTTPStatusCode': 200,\n",
       "  'RequestId': '2bc9fada-b81d-4a48-973a-a902dc8e1fda',\n",
       "  'RetryAttempts': 0},\n",
       " 'StartTime': datetime.datetime(2019, 9, 10, 11, 12, 10, 284000, tzinfo=tzlocal()),\n",
       " 'Status': 'LAUNCHING',\n",
       " 'TaskExecutionArn': 'arn:aws:datasync:us-west-2:006326790825:task/task-0055ebc20dce044ea/execution/exec-0f6ff126a0b11395d'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.describe_task_execution(TaskExecutionArn=task_exec_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
